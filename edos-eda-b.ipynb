{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"8dfb4c0b3f6ac3a64d7a4572975dd3eb4bfd4b5491ce12660c6428802afd775b"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers --upgrade\n# !pip install datasets\n# !pip install numpy\n# !pip install pandas\n# !pip install matplotlib\n# !pip install scipy\n# !pip install sklearn\n#!pip install scikit-learn\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-04-17T16:31:07.807777Z","iopub.execute_input":"2023-04-17T16:31:07.808209Z","iopub.status.idle":"2023-04-17T16:31:26.779764Z","shell.execute_reply.started":"2023-04-17T16:31:07.808124Z","shell.execute_reply":"2023-04-17T16:31:26.778642Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nCollecting transformers\n  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nInstalling collected packages: huggingface-hub, transformers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.10.1\n    Uninstalling huggingface-hub-0.10.1:\n      Successfully uninstalled huggingface-hub-0.10.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.20.1\n    Uninstalling transformers-4.20.1:\n      Successfully uninstalled transformers-4.20.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.13.4 which is incompatible.\nallennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.28.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.13.4 transformers-4.28.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer,BertModel,BertConfig\nfrom transformers import ErnieModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom transformers import logging\nfrom transformers import RobertaTokenizer, RobertaModel\nfrom transformers import AlbertTokenizer, AlbertModel","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:26.782074Z","iopub.execute_input":"2023-04-17T16:31:26.782739Z","iopub.status.idle":"2023-04-17T16:31:35.138738Z","shell.execute_reply.started":"2023-04-17T16:31:26.782698Z","shell.execute_reply":"2023-04-17T16:31:35.137588Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.143723Z","iopub.execute_input":"2023-04-17T16:31:35.146326Z","iopub.status.idle":"2023-04-17T16:31:35.154522Z","shell.execute_reply.started":"2023-04-17T16:31:35.146284Z","shell.execute_reply":"2023-04-17T16:31:35.153549Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# #df = pd.read_csv('/kaggle/input/stop-edos/train_dev72.csv',engine='python')\n# df = pd.read_csv('/kaggle/input/edosb/train_dev.csv',engine='python')\n# df = pd.read_csv('/kaggle/input/edosb/train_test_b.csv',engine='python')\n\n# #df=df[0:3000]\n# df.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.164321Z","iopub.execute_input":"2023-04-17T16:31:35.166801Z","iopub.status.idle":"2023-04-17T16:31:35.234905Z","shell.execute_reply.started":"2023-04-17T16:31:35.166760Z","shell.execute_reply":"2023-04-17T16:31:35.233776Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#df = pd.read_csv('/kaggle/input/stop-edos/train_dev72.csv',engine='python')\ndf = pd.read_csv('/kaggle/input/edosb/train_dev.csv',engine='python')\n#df = pd.read_csv('/kaggle/input/edos-dev-task/dev_task_b_entries_eda.csv',engine='python')\n\n#df=df[0:3000]\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.236338Z","iopub.execute_input":"2023-04-17T16:31:35.236991Z","iopub.status.idle":"2023-04-17T16:31:35.359391Z","shell.execute_reply.started":"2023-04-17T16:31:35.236950Z","shell.execute_reply":"2023-04-17T16:31:35.358257Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 14695 entries, 0 to 14694\nData columns (total 3 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   rewire_id  14695 non-null  object\n 1   text       14695 non-null  object\n 2   label      14695 non-null  int64 \ndtypes: int64(1), object(2)\nmemory usage: 344.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df['label'].value_counts()\n# 2 含有贬义的言辞(或行为)\n# 3 仇恨; 愤怒; 敌意; 憎恶;\n# 4 偏见的讨论\n# 1 威胁，计划伤害和煽动","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.361870Z","iopub.execute_input":"2023-04-17T16:31:35.362964Z","iopub.status.idle":"2023-04-17T16:31:35.374339Z","shell.execute_reply.started":"2023-04-17T16:31:35.362890Z","shell.execute_reply":"2023-04-17T16:31:35.373031Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1    4770\n2    3495\n3    3330\n0    3100\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# df.loc[df['label_sexist']=='not sexist','label_sexist']=0\n# df.loc[df['label_sexist']=='sexist','label_sexist']=1\n\nfile1=np.array(df)\nx=[x[1] for x in file1]#text\ny=[int(x[2]) for x in file1]#label\nz=[int(x[0][19:]) for x in file1]# id\n\n#print(x,y,z)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.375886Z","iopub.execute_input":"2023-04-17T16:31:35.376490Z","iopub.status.idle":"2023-04-17T16:31:35.399505Z","shell.execute_reply.started":"2023-04-17T16:31:35.376449Z","shell.execute_reply":"2023-04-17T16:31:35.398455Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test, z_train, z_test =  train_test_split(x, y, z, test_size=0.1)\n#z_test","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.400997Z","iopub.execute_input":"2023-04-17T16:31:35.401353Z","iopub.status.idle":"2023-04-17T16:31:35.695635Z","shell.execute_reply.started":"2023-04-17T16:31:35.401318Z","shell.execute_reply":"2023-04-17T16:31:35.694673Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#df_dev=pd.read_csv('/kaggle/input/edos-dev-task/test_task_b_entries_eda.csv')\ndf_dev=pd.read_csv('/kaggle/input/stop-edos/dev_task_b_entries9_0.1_eda.csv')\n#df_dev=pd.read_csv('/kaggle/input/edos-dev-task/dev_task_b_entries.csv')\n#df_dev=pd.read_csv('/kaggle/input/stop-edos/stop_dev_task_b_entries_eda.csv')\ndf_dev.info()\n\nx_dev= df_dev['text'].tolist()\nz_dev=[int(x[19:]) for x in list(df_dev['rewire_id'])]","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.697305Z","iopub.execute_input":"2023-04-17T16:31:35.697702Z","iopub.status.idle":"2023-04-17T16:31:35.742910Z","shell.execute_reply.started":"2023-04-17T16:31:35.697665Z","shell.execute_reply":"2023-04-17T16:31:35.742003Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4860 entries, 0 to 4859\nData columns (total 2 columns):\n #   Column     Non-Null Count  Dtype \n---  ------     --------------  ----- \n 0   text       4860 non-null   object\n 1   rewire_id  4860 non-null   object\ndtypes: object(2)\nmemory usage: 76.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"#tokenizer = BertTokenizer.from_pretrained(\"nghuyong/ernie-2.0-large-en\")\n#tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n#tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2')\n#tokenizer = AlbertTokenizer.from_pretrained('albert-large-v2')\n#tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\ntokenizer = BertTokenizer.from_pretrained('bert-large-cased')","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:35.747147Z","iopub.execute_input":"2023-04-17T16:31:35.747716Z","iopub.status.idle":"2023-04-17T16:31:37.142834Z","shell.execute_reply.started":"2023-04-17T16:31:35.747687Z","shell.execute_reply":"2023-04-17T16:31:37.141978Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72bc5535342049a08e1c209f51582c9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa9fc745434c4783919857dbc990ecd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22b566a8840145ffac0d41ace34b52a9"}},"metadata":{}}]},{"cell_type":"code","source":"train_encoding = tokenizer(x_train, truncation=True, padding=True, max_length=50)\ntest_encoding = tokenizer(x_test, truncation=True, padding=True, max_length=50)\ndev_encoding=tokenizer(x_dev,truncation=True,padding=True, max_length=50)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:37.144117Z","iopub.execute_input":"2023-04-17T16:31:37.145105Z","iopub.status.idle":"2023-04-17T16:31:49.622701Z","shell.execute_reply.started":"2023-04-17T16:31:37.145068Z","shell.execute_reply":"2023-04-17T16:31:49.621734Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(train_encoding.keys())","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:49.627242Z","iopub.execute_input":"2023-04-17T16:31:49.629476Z","iopub.status.idle":"2023-04-17T16:31:49.642676Z","shell.execute_reply.started":"2023-04-17T16:31:49.629438Z","shell.execute_reply":"2023-04-17T16:31:49.641792Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 数据集封装和处理","metadata":{}},{"cell_type":"code","source":"# 数据集读取, 继承torch的Dataset类，方便后面用DataLoader封装数据集\nclass NewsDataset(Dataset):\n    def __init__(self, encodings, labels,ids):\n        self.encodings = encodings\n        self.labels = labels\n        self.ids=ids\n    \n    #这里的idx是为了让后面的DataLoader成批处理成迭代器，按idx映射到对应数据\n    def __getitem__(self, idx):\n        item = {key: torch.as_tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.as_tensor(int(self.labels[idx]))\n        item['ids']=torch.as_tensor(int(self.ids[idx]))\n        return item\n    \n    #数据集长度。通过len(这个实例对象)，可以查看长度\n    def __len__(self):\n        return len(self.labels)\n    \nclass DevDataset(Dataset):\n    def __init__(self, encodings,ids):\n        self.encodings = encodings\n        self.ids=ids\n    \n    #这里的idx是为了让后面的DataLoader成批处理成迭代器，按idx映射到对应数据\n    def __getitem__(self, idx):\n        item = {key: torch.as_tensor(val[idx]) for key,val in self.encodings.items()}\n         #item['encodings']=torch.as_tensor(self.encodings[idx])\n        item['ids']=torch.as_tensor(self.ids[idx])\n        return item\n    \n    #数据集长度。通过len(这个实例对象)，可以查看长度\n    def __len__(self):\n        return len(self.ids)\n    \n#将数据集包装成torch的Dataset形式\ntrain_dataset = NewsDataset(train_encoding, y_train,z_train)\ntest_dataset = NewsDataset(test_encoding, y_test,z_test)\ndev_dataset = DevDataset(dev_encoding,z_dev)\n# 单个读取到批量读取\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True)\ndev_dataloader=DataLoader(dev_dataset,batch_size=16,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:49.647048Z","iopub.execute_input":"2023-04-17T16:31:49.649648Z","iopub.status.idle":"2023-04-17T16:31:49.665020Z","shell.execute_reply.started":"2023-04-17T16:31:49.649606Z","shell.execute_reply":"2023-04-17T16:31:49.664087Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Model(torch.nn.Module):\n    def __init__(self, checkpoint=\"bert-large-uncased\"):\n        super().__init__()\n        #self.pretrained = ErnieModel.from_pretrained(\"nghuyong/ernie-2.0-large-en\")\n        #self.pretrained = RobertaModel.from_pretrained('roberta-large')\n        #self.pretrained = AlbertModel.from_pretrained(\"albert-xxlarge-v2\")\n        #self.pretrained = AlbertModel.from_pretrained(\"albert-large-v2\")\n        #self.pretrained = RobertaModel.from_pretrained('roberta-large')\n        self.pretrained = BertModel.from_pretrained(\"bert-large-cased\")\n        self.fc = torch.nn.Sequential(torch.nn.Linear(1024, 4))\n \n    def forward(self, input_ids, attention_mask):\n        logits = self.pretrained(input_ids=input_ids, attention_mask=attention_mask)\n        logits = logits.last_hidden_state[:, 0]\n        logits = self.fc(logits)\n        return logits\n    \n# class Config(object):\n\n#     def __init__(self):\n#         self.pre_bert_path=\"nghuyong/ernie-1.0\"\n#         self.train_path = 'data/dataset_train.csv'  # 训练集\n#         self.dev_path = 'data/dataset_valid.csv'  # 验证集\n#         self.test_path = 'data/test.csv'  # 测试集\n#         self.class_path = 'data/class.json'  # 类别名单\n#         self.save_path ='mymodel/ernie.pth'        # 模型训练结果\n#         self.num_classes=10\n#         self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n\n#         self.epochs = 10  # epoch数\n#         self.batch_size = 128  # mini-batch大小\n#         self.maxlen = 32  # 每句话处理成的长度(短填长切)\n#         self.learning_rate = 5e-4                                       # 学习率\n#         self.hidden_size=768\n#         self.tokenizer = AutoTokenizer.from_pretrained(self.pre_bert_path)\n\n# class Model(nn.Module):\n#     def __init__(self, config):\n#         super(Model, self).__init__()\n#         self.ernie=AutoModel.from_pretrained(config.pre_bert_path)\n#         #设置不更新预训练模型的参数\n#         for param in self.ernie.parameters():\n#             param.requires_grad = False\n#         self.fc = nn.Linear(config.hidden_size, config.num_classes)\n#     def forward(self, input):\n#         out=self.ernie(input_ids =input['input_ids'],attention_mask=input['attention_mask'],token_type_ids=input['token_type_ids'])\n#         #只取最后一层CLS对应的输出\n#         out = self.fc(out.pooler_output)\n#         return out","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:49.669868Z","iopub.execute_input":"2023-04-17T16:31:49.670219Z","iopub.status.idle":"2023-04-17T16:31:49.684478Z","shell.execute_reply.started":"2023-04-17T16:31:49.670186Z","shell.execute_reply":"2023-04-17T16:31:49.683446Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## 实例化模型、定义损失函数和优化器","metadata":{}},{"cell_type":"code","source":"from torch.autograd import Variable\nfrom torch.nn import functional as F\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device,'能用')\n\n\nmodel = Model().to(device)\n\nclass FocalLoss(nn.Module):\n    #def __init__(self, class_num, alpha=[0.33,0.67], gamma=2, use_alpha=True, size_average=True):\n    #8360\n    #def __init__(self, class_num, alpha=[0.34,0.66], gamma=2, use_alpha=True, size_average=True):\n    #83.6\n    #def __init__(self, class_num, alpha=[0.35,0.65], gamma=2, use_alpha=True, size_average=True):\n    #83.2\n    \n    #def __init__(self, class_num, alpha=[0.3,0.2,0.2,0.3], gamma=2, use_alpha=True, size_average=True):\n    #0.9265 0.623   \n    #def __init__(self, class_num, alpha=[0.41,0.39,0.12,0.08], gamma=2, use_alpha=True, size_average=True):\n    #0.906 0.592\n    #def __init__(self, class_num, alpha=[0.35,0.14,0.18,0.33], gamma=2, use_alpha=True, size_average=True):\n    #0.902 0.618\n    #def __init__(self, class_num, alpha=[0.32,0.2,0.24,0.28], gamma=2, use_alpha=True, size_average=True):\n    #0.922 0.588\n    #def __init__(self, class_num, alpha=[0.28,0.22,0.22,0.28], gamma=2, use_alpha=True, size_average=True):\n    #0.924 0.626\n    \n    #def __init__(self, class_num, alpha=[0.32,0.20,0.22,0.28], gamma=2, use_alpha=True, size_average=True):\n    #0.919 0.666\n    #stop 0.891 0.648\n    #def __init__(self, class_num, alpha=[0.31,0.19,0.21,0.29], gamma=2, use_alpha=True, size_average=True):\n    #0.918 0.667\n    \n    #def __init__(self, class_num, alpha=[0.328,0.213,0.291,0.305], gamma=2, use_alpha=True, size_average=True):\n    #0.88 0.68\n    def __init__(self, class_num, alpha=[0.328,0.213,0.291,0.305], gamma=2, use_alpha=False, size_average=True):\n    #\n        super(FocalLoss, self).__init__()\n        self.class_num = class_num\n        self.alpha = alpha\n        self.gamma = gamma\n        if use_alpha:\n            self.alpha = torch.tensor(alpha).cuda()\n        self.softmax = nn.Softmax(dim=1)\n        self.use_alpha = use_alpha\n        self.size_average = size_average\n        #super(Module, self).__init__()\n    def forward(self, pred, target):\n        prob = self.softmax(pred.view(-1,self.class_num))\n        prob = prob.clamp(min=0.0001,max=1.0)\n        target_ = torch.zeros(target.size(0),self.class_num).cuda()\n        target_.scatter_(1, target.view(-1, 1).long(), 1.)\n        if self.use_alpha:\n            batch_loss = - self.alpha.double() * torch.pow(1-prob,self.gamma).double() * prob.log().double() * target_.double()\n        else:\n            batch_loss = - torch.pow(1-prob,self.gamma).double() * prob.log().double() * target_.double()\n        batch_loss = batch_loss.sum(dim=1)\n        if self.size_average:\n            loss = batch_loss.mean()\n        else:\n            loss = batch_loss.sum()\n        return loss\n\ncriterion = FocalLoss(class_num=4)\n    \n# 优化方法\n#过滤掉被冻结的参数，反向传播需要更新的参数\noptim = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\ntotal_steps = len(train_loader) * 1\nscheduler = get_linear_schedule_with_warmup(optim, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:31:49.686899Z","iopub.execute_input":"2023-04-17T16:31:49.687506Z","iopub.status.idle":"2023-04-17T16:32:10.029166Z","shell.execute_reply.started":"2023-04-17T16:31:49.687468Z","shell.execute_reply":"2023-04-17T16:32:10.026921Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"cuda 能用\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6f00dcc84948b4a4dc554593f191f8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 定义训练函数","metadata":{}},{"cell_type":"code","source":"from statistics import mean\ndef calculate_f1(stacked):\n    stacked=torch.as_tensor(stacked,dtype=torch.int64)\n    cmt=torch.zeros(4,4,dtype=torch.int32)\n    #cmt\n    for p in stacked:\n        tl,pl=p.tolist()\n        cmt[tl,pl]=cmt[tl,pl]+1\n    M=cmt\n    n = len(M)\n    pre_all=[]\n    rec_all=[]\n    f1_all=[]\n    sum_acc=0\n    for i in range(len(M[0])):\n        rowsum, colsum = sum(M[i]), sum(M[r][i] for r in range(n))\n        try:\n            precision=float(M[i][i]/float(colsum))\n            pre_all.append(precision)\n            print(float(M[i][i]))\n            print(float(colsum))\n            recall=float(M[i][i]/float(rowsum))\n            rec_all.append(recall)\n            f1=2*(precision*recall)/(precision+recall)\n            f1_all.append(f1)\n\n            sum_acc+=M[i][i].item()\n        except ZeroDivisionError:\n            print('precision: %s' % 0, 'recall: %s' % 0)\n    print(cmt)\n    accuracy=sum_acc/((sum(M).sum()).item())\n    print('accuracy:%s' % accuracy ,'precision: %s' % (mean(pre_all)), 'recall: %s' % (mean(rec_all)),'F1: %s ' % (mean(f1_all)))","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:32:10.030659Z","iopub.execute_input":"2023-04-17T16:32:10.032218Z","iopub.status.idle":"2023-04-17T16:32:10.044031Z","shell.execute_reply.started":"2023-04-17T16:32:10.032176Z","shell.execute_reply":"2023-04-17T16:32:10.043135Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# none                                        10602\n# 2. derogation                                1590\n# 3. animosity                                 1165\n# 4. prejudiced discussions                     333\n# 1. threats, plans to harm and incitement\ndef save_to_csv(stacked):\n    stacked=torch.as_tensor(stacked).cpu()\n    t_np = stacked.numpy() #convert to Numpy array\n    df = pd.DataFrame(t_np) #convert to a dataframe\n    \n    df.columns=['rewire_id', 'label_pred']\n    df['rewire_id']=['sexism2022_english-'+str(x) for x in df['rewire_id']]\n    \n    df.loc[df['label_pred']==0,'label_pred']='1. threats, plans to harm and incitement'\n    df.loc[df['label_pred']==1,'label_pred']='2. derogation'\n    df.loc[df['label_pred']==2,'label_pred']='3. animosity'\n    df.loc[df['label_pred']==3,'label_pred']='4. prejudiced discussions'\n\n    print(df)\n    df.to_csv(\"/kaggle/working/testroberta.csv\",index=False) #save to file\n    df.info()\n    print(\"保存成功！\")\n    #Then, to reload:","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:32:10.045467Z","iopub.execute_input":"2023-04-17T16:32:10.045836Z","iopub.status.idle":"2023-04-17T16:32:10.059594Z","shell.execute_reply.started":"2023-04-17T16:32:10.045802Z","shell.execute_reply":"2023-04-17T16:32:10.058658Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# 精度计算\n#imports untils\nfrom sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\nbatch_size=16\ndef validation():\n    model.eval()\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    with torch.no_grad():\n        results=torch.zeros(0).to(device)\n        label_all=torch.zeros(0).to(device)\n        id_all=torch.zeros(0).to(device)\n        for batch in test_dataloader:\n            # 正常传播\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            ids=batch['ids'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n            loss = criterion(outputs, labels)\n            total_eval_loss += loss.item()\n            logits = outputs\n            \n            # 获取预测结果\n            preds = outputs.argmax(1).to(device)\n            results=torch.cat((results,preds),dim=0)#预测的结果\n            \n            label_all=torch.cat((label_all,labels),dim=0)\n            id_all=torch.cat((id_all,ids),dim=0)\n            \n        stacked=torch.stack(\n                (\n                    torch.as_tensor(label_all).to(device),\n                    torch.as_tensor(list(map(int,results))).to(device)\n                )\n            )\n        stacked=stacked.t()\n        calculate_f1(stacked)\n        \n#         stacked_saved=torch.stack(\n#                     (\n#                         torch.as_tensor(list(map(int,id_all))).to(device),\n#                         torch.as_tensor(list(map(int,label_all))).to(device),#真实结果\n#                         torch.as_tensor(list(map(int,results))).to(device)#预测结果\n#                     )\n#                 )\n#         stacked_saved=stacked_saved.t()\n#         save_to_csv(stacked_saved)\n        \n        #print(stacked_saved)\n    print(\"Average testing loss: %.4f\"%(total_eval_loss/len(test_dataloader)))\n    print(\"-------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:32:10.061156Z","iopub.execute_input":"2023-04-17T16:32:10.061503Z","iopub.status.idle":"2023-04-17T16:32:10.076708Z","shell.execute_reply.started":"2023-04-17T16:32:10.061466Z","shell.execute_reply":"2023-04-17T16:32:10.075648Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train():\n    batch_size=16\n    for epoch in range(1):\n        print(\"------------Epoch: %d ----------------\" % epoch)\n        train_loss = 0.0 # 训练损失\n        val_loss = 0.0 # 验证损失\n        model.train() # 声明开始训练\n        total_train_loss = 0\n        iter_num = 0\n        total_iter = len(train_loader)\n        \n        results=torch.zeros(0).to(device)\n        label_all=torch.zeros(0).to(device)\n        ids_all=torch.zeros(0).to(device)\n        for batch in train_loader:\n            # 正向传播\n            optim.zero_grad()\n            #print(batch)\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            ids=batch['ids'].to(device)\n            \n            outputs = model(input_ids, attention_mask=attention_mask)\n\n            loss = criterion(outputs, labels)    \n\n            total_train_loss += loss.item()\n\n            loss.backward()# 反向传播\n            nn.utils.clip_grad_norm_(model.parameters(), 1.0)   #梯度裁剪，防止梯度爆炸  \n            \n            # 获取预测结果\n            preds = outputs.argmax(1).to(device)\n            \n            # # 选取最后的结果。。。。。。。。。（这里最后需要计算一下混淆矩阵和f1）\n            # label_all=torch.cat((label_all,ids),dim=0)\n            # results=torch.cat((results,preds),dim=0)#预测的结果\n            # ids_all=torch.cat((ids_all,ids),dim=0)\n\n\n            # 参数更新\n            optim.step()\n            scheduler.step()\n\n            iter_num += 1\n            if(iter_num % 100==0):\n                print(\"epoth: %d, iter_num: %d, loss: %.4f, %.2f%%\" % (epoch, iter_num, loss.item(), iter_num/total_iter*100))\n        print(\"Epoch: %d, Average training loss: %.4f\"%(epoch, total_train_loss/len(train_loader)))     \n                \n        validation()\n        \n        model.eval()\n        print(\"--------------开始分类test集-----------------\")\n        with torch.no_grad():\n            results=torch.zeros(0).to(device)\n            #label_all=torch.zeros(0).to(device)\n            ids_all=torch.zeros(0).to(device)\n            for batch in dev_dataloader:\n                # 正常传播\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                #labels = batch['labels'].to(device)\n                ids=batch['ids'].to(device)\n\n                outputs = model(input_ids, attention_mask=attention_mask)\n                \n\n                # 获取预测结果\n                preds = outputs.argmax(1).to(device)\n                results=torch.cat((results,preds),dim=0)#预测的结果\n                ids_all=torch.cat((ids_all,ids),dim=0)\n\n            stacked_saved=torch.stack(\n                        (\n                            torch.as_tensor(list(map(int,ids_all))).to(device),\n                            torch.as_tensor(list(map(int,results))).to(device)#预测结果\n                        )\n                    )\n            stacked_saved=stacked_saved.t()\n            save_to_csv(stacked_saved)\n\n        print(\"--------------test完成-----------------\")\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:32:10.078276Z","iopub.execute_input":"2023-04-17T16:32:10.078638Z","iopub.status.idle":"2023-04-17T16:32:10.094958Z","shell.execute_reply.started":"2023-04-17T16:32:10.078603Z","shell.execute_reply":"2023-04-17T16:32:10.093991Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2023-04-17T16:32:10.096534Z","iopub.execute_input":"2023-04-17T16:32:10.096885Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"------------Epoch: 0 ----------------\nepoth: 0, iter_num: 100, loss: 0.7159, 12.09%\nepoth: 0, iter_num: 200, loss: 0.2106, 24.18%\nepoth: 0, iter_num: 300, loss: 0.1621, 36.28%\nepoth: 0, iter_num: 400, loss: 0.1856, 48.37%\nepoth: 0, iter_num: 500, loss: 0.1076, 60.46%\nepoth: 0, iter_num: 600, loss: 0.1419, 72.55%\nepoth: 0, iter_num: 700, loss: 0.0368, 84.64%\nepoth: 0, iter_num: 800, loss: 0.0602, 96.74%\nEpoch: 0, Average training loss: 0.2675\n320.0\n332.0\n432.0\n523.0\n255.0\n311.0\n279.0\n304.0\ntensor([[320,   3,   1,   1],\n        [  8, 432,  53,  16],\n        [  3,  83, 255,   8],\n        [  1,   5,   2, 279]], dtype=torch.int32)\naccuracy:0.8748299319727891 precision: 0.8818895369768143 recall: 0.8840306997299194 F1: 0.8820559581029253 \nAverage testing loss: 0.1031\n-------------------------------\n--------------开始分类test集-----------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# 读文件 选取最后的结果\n# 直接将dev_label与最后的结果比较\ndf_pred = pd.read_csv('/kaggle/working/testroberta.csv',engine='python')# 直接读取结果\ndf_pred.info()\ndf_pred.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 结果是单dev集，直接计算f1\ndef dev_f1():\n    df_true=pd.read_csv('/kaggle/input/edos-dev-task/dev_task_b_labels.csv',engine='python')\n    df_data=pd.merge(df_pred,df_true,on='rewire_id')\n    df=df_data.sort_values(by=['rewire_id'],ascending=False)\n\n    df.loc[df['label_pred'].notnull(),'label_pred_0'] = df['label_pred'].str[0]\n    df.loc[df['label'].notnull(),'label_true_0'] = df['label'].str[0]\n    #print(df)\n    #print(type(df['label_true_0']))\n    file1=np.array(df)\n    pred=[int(x[3])-1 for x in file1]#pred\n    true=[int(x[4])-1 for x in file1]#true\n    #print(type(pred))\n\n    stacked=torch.stack(\n                    (\n                        torch.as_tensor(pred).to(device),\n                        torch.as_tensor(true).to(device)\n                    )\n                )\n    stacked=stacked.t()\n    #print(stacked)\n    calculate_f1(stacked)\n    print('---------------f1_score-----------------------')\n    print(f1_score(true,pred, average='macro'))\n    \n#dev_f1()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 结果是test集，直接生成output\nfrom scipy import stats\ndef eda_pred_set(df_pred):\n    # 定义函数，做分组聚合    \n    def func(df):\n        return stats.mode(df.values)[0][0]\n    # 给DataFrame应用函数\n    df_pred.loc[df_pred['label_pred'].notnull(),'label_pred'] = df_pred['label_pred']\n    df_pred = df_pred.groupby(by='rewire_id').agg(func).reset_index()\n#     df.loc[df['label_pred']==0,'label_pred']='1. threats, plans to harm and incitement'\n#     df.loc[df['label_pred']==1,'label_pred']='2. derogation'\n#     df.loc[df['label_pred']==2,'label_pred']='3. animosity'\n#     df.loc[df['label_pred']==3,'label_pred']='4. prejudiced discussions'\n    \n    df_pred.to_csv(\"/kaggle/working/bert.csv\",index=False)\n    df_pred.info()\n    df_pred.head()\n    return df_pred\n\ndf_pred = pd.read_csv('/kaggle/working/testroberta.csv',engine='python')# 直接读取结果\neda_pred_set(df_pred)\ndf_pred.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 结果是多dev集，先set，再计算f1\ndef eda_dev_f1(df_pred):\n    df_pred=eda_pred_set(df_pred)\n    df_true=pd.read_csv('/kaggle/input/edos-dev-task/dev_task_b_labels.csv',engine='python')\n    df_data=pd.merge(df_pred,df_true,on='rewire_id')\n    df=df_data.sort_values(by=['rewire_id'],ascending=False)\n\n    df.loc[df['label_pred'].notnull(),'label_pred_0'] = df['label_pred'].str[0]\n    df.loc[df['label'].notnull(),'label_true_0'] = df['label'].str[0]\n    print(df)\n\n    #print(type(df['label_true_0']))\n    file1=np.array(df)\n    pred=[int(x[3])-1 for x in file1]#pred\n    true=[int(x[4])-1 for x in file1]#true\n    #print(type(pred))\n\n    stacked=torch.stack(\n                    (\n                        torch.as_tensor(list(map(int,pred))).to(device),\n                        torch.as_tensor(list(map(int,true))).to(device)\n                    )\n                )\n    stacked=stacked.t()\n    #print(stacked)\n    calculate_f1(stacked)\n    print('---------------f1_score-----------------------')\n    print(f1_score(true,pred, average='macro'))\neda_dev_f1(df_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 众数1:\n    from scipy import stats\n\nstats.mode(nums)[0][0]\n\n众数2：\nimport numpy as np\n\ncounts = np.bincount(nums)\n#返回众数\nnp.argmax(counts)","metadata":{}}]}